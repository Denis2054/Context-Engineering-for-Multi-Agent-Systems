# Context Engineering for Multi-Agent Systems
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
<h3 align="center">
Move beyond prompting to build a Context Engine in a transparent architecture of context and reasoning
</h3>


<img src="./Chapter10/universal_context_engine.png" alt="Universal Context Engine Blueprint" width="40%" align="left" style="margin-right: 20px;">

[**ğŸï¸â–¶ï¸**](https://denis2054.github.io/Context-Engineering-for-Multi-Agent-Systems/media/player.html) **In 21stâ€‘century Agentic AI, Naturalâ€‘Languageâ€‘Programmed LLMs are the agents, and the domainâ€‘agnostic dualâ€‘RAG MAS is the environment they operate in.**
This repository provides a production-ready blueprint for the Agentic Era, allowing you to replace rigid, hard-coded workflows with a dynamic, **transparent**, **observable**, and **sovereign** **Context Engine**. By building universal, domain-agnostic Multi-Agent Systems through high-level semantic orchestration, you can save thousands of lines of code while maintaining 100% observability.

<br clear="left"/>
<p align="center">Copyright 2025-26, Denis Rothman. Last updated: February 11, 2026</p>
<p align="center">See the <a href="./CHANGELOG.md">Changelog</a> for updates, fixes, and upgrades(past, present, coming).</p>

Save thousands of lines of code by building universal, domain-agnostic Multi-Agent Systems (MAS) using the ultimate new programming language:
[**ğŸ›°ï¸ View Software Evolution Timeline**](https://denis2054.github.io/Context-Engineering-for-Multi-Agent-Systems/media/index.html)

ğŸ¬ January 24, 2026 Release:
**Sovereign Universal Context Engine**: A new **Glass Box Context Engine** implementation - `Chapter10/Universal_Context_Engine.ipynb` and `Chapter10/Universal_Context_Engine_UI.ipynb`- demonstrating **domain-agnostic architecture** by running *cross-domain* use cases on the same core.
**Token Analytics**: engine.py and the Dashboard provide rigorous transparency into token usage (Input, Output, Difference) for cost and verbosity analysis.

### ğŸ”§ LLM API Update

For a detailed list of affected notebooks and all changes, see the  â¡ï¸ [CHANGELOG.md](./CHANGELOG.md)

**LLM API update:**  
Several notebooks have been upgraded to use **GPTâ€‘5.1** along with the latest OpenAI library standards.  
These improvements provide *better performance, lower reasoning latency,* and more reliable handling of structured agent outputs.

This update also includes fixes to the **Moderation API**, ensuring safer and more robust processing of multiâ€‘agent interactions.

**Alternative: Sovereign AI Without External LLM APIs:**

If you prefer not to rely on an external LLM API, a full **DeepSeekâ€‘R1 Sovereign AI Implementation Guide** (with code) is available:

â¡ï¸ **[DeepSeekâ€‘R1 Sovereign AI Guide](https://github.com/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/sovereign_ai/README.md)**

</p>

<br>
<p align="center">
  <strong>ğŸš€ NEW: Interactive Trace Dashboard</strong><br>
  <em>Available in the Context Engine Room of Chapters 8 & 9: Visualize agent reasoning with our new HTML-based trace renderer.</em><br>
  <img src="./Chapter08/dashboard_concept.svg" alt="New Interactive Dashboard" width="80%">
</p>

<p align="center">
Denis Rothman</p>

<p align="center">
   <a href="https://packt.link/I1tSU" alt="Discord" title="Learn more on the Discord server"><img width="32px" src="https://cliply.co/wp-content/uploads/2021/08/372108630_DISCORD_LOGO_400.gif"/></a>
  &#8287;&#8287;&#8287;&#8287;&#8287;
  <a href="https://packt.link/free-ebook/9781806690053"><img width="32px" alt="Free PDF" title="Free PDF" src="https://cdn-icons-png.flaticon.com/512/4726/4726010.png"/></a>
 &#8287;&#8287;&#8287;&#8287;&#8287;
  <a href="https://packt.link/gbp/9781806690053"><img width="32px" alt="Graphic Bundle" title="Graphic Bundle" src="https://cdn-icons-png.flaticon.com/512/2659/2659360.png"/></a>
  &#8287;&#8287;&#8287;&#8287;&#8287;
   <a href="https://www.amazon.com/Context-Engineering-Multi-Agent-Systems-architecture/dp/1806690055/ref=tmm_pap_swatch_0?_encoding=UTF8&sr=8-3"><img width="32px" alt="Amazon" title="Get your copy" src="https://cdn-icons-png.flaticon.com/512/15466/15466027.png"/></a>
  &#8287;&#8287;&#8287;&#8287;&#8287;
</p>
<details open> 
 <summary><h2>About the book</h2></summary>.
<a href="https://www.packtpub.com/en-us/product/context-engineering-for-multi-agent-systems-9781806690046">
<img src="https://m.media-amazon.com/images/I/419o1BGjp0L.jpg" alt="Context Engineering  for Multi-Agent Systems, First Edition" height="1000px" align="right">
</a>

Generative AI is powerful, yet often unpredictable. This guide shows you how to turn that unpredictability into reliability by thinking beyond prompts and approaching AI like an architect. At its core is the Context Engine, a glass-box, multi-agent system youâ€™ll learn to design, strengthen, and apply across real-world scenarios.
Written by an AI guru and author of various cutting-edge AI books, this book takes you on a hands-on journey from the foundations of context design to building a fully operational Context Engine. Instead of relying on brittle prompts that give only simple instructions, youâ€™ll begin with semantic blueprints that map goals and roles with precision, then orchestrate specialized agents using the Model Context Protocol (MCP). As the engine evolves, youâ€™ll integrate memory and high-fidelity retrieval with citations, implement safeguards against data poisoning and prompt injection, and enforce moderation to keep outputs aligned with policy. Youâ€™ll also harden the system into a resilient architecture, then see it pivot seamlessly across domains, from legal compliance to strategic marketing, proving its domain independence.
By the end of this book, youâ€™ll be equipped with the skills needed to engineer an adaptable, verifiable architecture you can repurpose across domains and deploy with confidence.
</details>

<details open>
<summary><h2>Key Architecture Highlights</h2></summary>
<ul>
<li><strong>Glass Box Architecture:</strong> Provides 100% observability into agent reasoning through interactive trace dashboards and detailed execution logs.</li>
<li><strong>Universal Context Engine:</strong> A domain-agnostic core that runs cross-domain use cases (e.g., Legal and Marketing) without changing a single line of code.</li>
<li><strong>Dual High-Fidelity RAG:</strong> Implements research agents(dual: instructions and facts) with automated input sanitization and source-verifiable citations to ensure accuracy and defense.</li>
<li><strong> Telemetryâ€‘driven context layers:</strong> Continuous ingestion and structuring of environmental signals that form the dynamic operational context for multiâ€‘agent reasoning.</li>
<li><strong>Protocol-Driven:</strong> Orchestrates specialized agents using the Model Context Protocol (MCP) for seamless, modular multi-agent workflows.</li>
<li><strong>Token & Cost Analytics:</strong> Integrated tracking of input/output tokens to monitor cost-efficiency and model verbosity at every step.</li>
</ul>
</details>

<details open> 
  <summary><h2>Key Learnings</summary>
<ul>
<li>Develop memory models to retain short-term and cross-session context</li>
<li>Craft semantic blueprints and drive multi-agent orchestration with MCP</li>
<li>Implement high-fidelity RAG pipelines with verifiable citations</li>
<li>Apply safeguards against prompt injection and data poisoning</li>
<li>Enforce moderation and policy-driven control in AI workflows</li>
<li>Repurpose the Context Engine across legal, marketing, and beyond</li>
<li>Deploy a scalable, observable Context Engine in production</li>
</ul>
  </details>

<details open> 
<summary><h2>ğŸ¥ Deep Dive: Architecture â†’ Context â†’ Agents â†’ Code</summary>

This recorded session walks through the entire stack behind the sentence:
**â€œIn 21stâ€‘century Agentic AI, Naturalâ€‘Languageâ€‘Programmed LLMs are the agents, and the domainâ€‘agnostic dualâ€‘RAG MAS is the environment they operate in.â€**
The deep dive unpacks each term stepâ€‘byâ€‘step:   
- **21stâ€‘century Agentic AI** â€” why agents are naturalâ€‘languageâ€‘programmed programs     
- **LLMs as agents** â€” how reasoning, memory, and protocols turn models into actors     
- **Domainâ€‘agnostic Context Engine** â€” the universal core that runs any use case     
- **Dualâ€‘RAG MAS** â€” the twoâ€‘channel research architecture (instructions + facts)     
- **Environment design** â€” how telemetry, context layers, and MCP orchestrate agents     
- **Full drillâ€‘down to code** â€” notebooks, pipelines, and execution traces     
- **Full climb back up** â€” how the code reâ€‘forms the architecture endâ€‘toâ€‘end     
[ğŸ“º**Watch the full deep dive on LinkedIn**](https://www.linkedin.com/posts/denis-rothman_ai-agenticera-contextengineering-activity-7424026873652850688-eXw8)   
If you are an architect or lead looking for:   
âœ… ROI & Domain Agnosticism logic  
âœ… Glass-Box Observability traces  
âœ… Sovereign RAG blueprints   
Join the engineering discussion here: [**Link to GitHub Discussion**](https://github.com/Denis2054/Context-Engineering-for-Multi-Agent-Systems/discussions/2)

</details> 
 
<details open> 
<summary><h2>Chapters: From Architecture to code</h2></summary>

| Chapters | Colab | Kaggle |  Studio Lab |
| :-------- | :-------- | :------- | :-------- |
| **Chapter 1: From Prompts to Context: Building the Semantic Blueprint** | | | |
| <ul><li>SLR.ipynb</li></ul> | <a href="https://colab.research.google.com/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter01/SLR.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a><br> | <a href="https://www.kaggle.com/kernels/welcome?src=https://github.com/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter01/SLR.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a><br> | <a href="https://studiolab.sagemaker.aws/import/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter01/SLR.ipynb"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open In Studio Lab"></a><br> |
| <ul><li>Use_Case.ipynb</li></ul> | <a href="https://colab.research.google.com/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter01/Use_Case.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a><br> | <a href="https://www.kaggle.com/kernels/welcome?src=https://github.com/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter01/Use_Case.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a><br> | <a href="https://studiolab.sagemaker.aws/import/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter01/Use_Case.ipynb"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open In Studio Lab"></a><br> |
| **Chapter 2: Building a Multi-Agent System with MCP** | | | |
| <ul><li>MAS_MCP.ipynb</li></ul> | <a href="https://colab.research.google.com/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter02/MAS_MCP.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a><br> | <a href="https://www.kaggle.com/kernels/welcome?src=https://github.com/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter02/MAS_MCP.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a><br> |<a href="https://studiolab.sagemaker.aws/import/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter02/MAS_MCP.ipynb"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open In Studio Lab"></a><br> |
| <ul><li>MAS_MCP_control.ipynb</li></ul> | <a href="https://colab.research.google.com/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter02/MAS_MCP_control.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a><br> | <a href="https://www.kaggle.com/kernels/welcome?src=https://github.com/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter02/MAS_MCP_control.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a><br> | <a href="https://studiolab.sagemaker.aws/import/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter02/MAS_MCP_control.ipynb"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open In Studio Lab"></a><br> |
| **Chapter 3: Building the Context-Aware Multi-Agent System** | | | |
| <ul><li>RAG_Pipeline.ipynb</li></ul> | <a href="https://colab.research.google.com/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter03/RAG_Pipeline.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a><br> | <a href="https://www.kaggle.com/kernels/welcome?src=https://github.com/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter03/RAG_Pipeline.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a><br> | <a href="https://studiolab.sagemaker.aws/import/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter03/RAG_Pipeline.ipynb"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open In Studio Lab"></a><br> |
| <ul><li>Context_Aware_MAS.ipynb</li></ul> | <a href="https://colab.research.google.com/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter03/Context_Aware_MAS.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a><br> | <a href="https://www.kaggle.com/kernels/welcome?src=https://github.com/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter03/Context_Aware_MAS.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a><br> | <a href="https://studiolab.sagemaker.aws/import/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter03/Context_Aware_MAS.ipynb"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open In Studio Lab"></a><br> |
| **Chapter 4: Assembling the Context Engine** | | | |
| <ul><li>Context_Engine.ipynb</li></ul> | <a href="https://colab.research.google.com/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter04/Context_Engine.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a><br> | <a href="https://www.kaggle.com/kernels/welcome?src=https://github.com/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter04/Context_Engine.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a><br> | <a href="https://studiolab.sagemaker.aws/import/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter04/Context_Engine.ipynb"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open In Studio Lab"></a><br> |
| **Chapter 5: Hardening the Context Engine** | | | |
| <ul><li>Context_Engine_MAS_MCP.ipynb</li></ul> | <a href="https://colab.research.google.com/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter05/Context_Engine_MAS_MCP.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a><br> | <a href="https://www.kaggle.com/kernels/welcome?src=https://github.com/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter05/Context_Engine_MAS_MCP.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a><br> | <a href="https://studiolab.sagemaker.aws/import/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter05/Context_Engine_MAS_MCP.ipynb"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open In Studio Lab"></a><br> |
| <ul><li>Context_Engine_Pre_Production.ipynb</li></ul> | <a href="https://colab.research.google.com/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter05/Context_Engine_Pre_Production.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a><br> | <a href="https://www.kaggle.com/kernels/welcome?src=https://github.com/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter05/Context_Engine_Pre_Production.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a><br> | <a href="https://studiolab.sagemaker.aws/import/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter05/Context_Engine_Pre_Production.ipynb"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open In Studio Lab"></a><br> |
| **Chapter 6: Building the Summarizer Agent for Context Reduction** | | | |
| <ul><li>Context_Engine_Content_Reduction.ipynb</li></ul> | <a href="https://colab.research.google.com/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter06/Context_Engine_Content_Reduction.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a><br> | <a href="https://www.kaggle.com/kernels/welcome?src=https://github.com/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter06/Context_Engine_Content_Reduction.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a><br> | <a href="https://studiolab.sagemaker.aws/import/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter06/Context_Engine_Content_Reduction.ipynb"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open In Studio Lab"></a><br> |
| **Chapter 7: High-Fidelity RAG and Defense: The NASA-Inspired Research Assistant** | | | |
Domainâ€‘agnostic Universal Context Engine architectures are powered by environmentâ€‘ingestion agents illustrated in `High_Fidelity_Data_Ingestion.ipynb`that dynamically construct the operational context for complex, crossâ€‘domain agentic systems.
| <ul><li>High_Fidelity_Data_Ingestion.ipynb</li></ul> | <a href="https://colab.research.google.com/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter07/High_Fidelity_Data_Ingestion.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a><br> | <a href="https://www.kaggle.com/kernels/welcome?src=https://github.com/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter07/High_Fidelity_Data_Ingestion.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a><br> | <a href="https://studiolab.sagemaker.aws/import/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter07/High_Fidelity_Data_Ingestion.ipynb"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open In Studio Lab"></a><br> |
Domainâ€‘agnostic Universal Context Engine architectures are also driven by MASâ€‘RAGâ€‘Context Engines, illustrated in `NASA_Research_Assistant_and_Retrocompatibility.ipynb`, which combine highâ€‘fidelity retrieval, defense, and multiâ€‘agent reasoning into a unified operational environment.
| <ul><li>NASA_Research_Assistant_and_Retrocompatibility.ipynb</li></ul> | <a href="https://colab.research.google.com/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter07/NASA_Research_Assistant_and_Retrocompatibility.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a><br> | <a href="https://www.kaggle.com/kernels/welcome?src=https://github.com/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter07/NASA_Research_Assistant_and_Retrocompatibility.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a><br> | <a href="https://studiolab.sagemaker.aws/import/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter07/NASA_Research_Assistant_and_Retrocompatibility.ipynb"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open In Studio Lab"></a><br> |
| **Chapter 8: Architecting for Reality: Moderation, Latency, and Policy-Driven AI** | | | |
| <ul><li>Data_Ingestion.ipynb</li></ul> | <a href="https://colab.research.google.com/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter08/Data_Ingestion.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a><br> | <a href="https://www.kaggle.com/kernels/welcome?src=https://github.com/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter08/Data_Ingestion.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a><br> | <a href="https://studiolab.sagemaker.aws/import/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter08/Data_Ingestion.ipynb"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open In Studio Lab"></a><br> |
| <ul><li>Legal_assistant_Explorer.ipynb</li></ul> | <a href="https://colab.research.google.com/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter08/Legal_assistant_Explorer.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a><br> | <a href="https://www.kaggle.com/kernels/welcome?src=https://github.com/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter08/Legal_assistant_Explorer.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a><br> | <a href="https://studiolab.sagemaker.aws/import/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter08/Legal_assistant_Explorer.ipynb"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open In Studio Lab"></a><br> |
| **Chapter 9: Architecting for Brand and Agility: The Strategic Marketing Engine** | | | | |
| <ul><li>Data_Ingestion_Marketing.ipynb</li></ul> | <a href="https://colab.research.google.com/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter09/Data_Ingestion_Marketing.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a><br> | <a href="https://www.kaggle.com/kernels/welcome?src=https://github.com/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter09/Data_Ingestion_Marketing.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a><br> | <a href="https://studiolab.sagemaker.aws/import/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter09/Data_Ingestion_Marketing.ipynb"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open In Studio Lab"></a><br> |
| <ul><li>Marketing_Assistant.ipynb</li></ul> | <a href="https://colab.research.google.com/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter09/Marketing_Assistant.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a><br> | <a href="https://www.kaggle.com/kernels/welcome?src=https://github.com/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter09/Marketing_Assistant.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a><br> | <a href="https://studiolab.sagemaker.aws/import/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter09/Marketing_Assistant.ipynb"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open In Studio Lab"></a><br> |
| **Chapter 10: The Blueprint for Production-Ready AI** | | | |
The Universal Context Engine provides full **architectural sovereignty** through *glassâ€‘box reasoning*, *verifiable multiâ€‘agent traces*, and complete *control over memory*, *dual RAG*, *moderation*, and *orchestration*. Its **domainâ€‘agnostic core** can be deployed in restricted, *missionâ€‘critical*, *strategic environments* where transparency, auditability, and **sovereignty are mandatory**.
The `Universal_Context_Engine.ipynb` version runs a list of explicit scenarios for batch processing.
| <ul><li>ğŸ¬Universal_Context_Engine.ipynb - January 24,2026 release</li></ul> | <a href="https://colab.research.google.com/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter10/Universal_Context_Engine.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a><br> | <a href="https://www.kaggle.com/kernels/welcome?src=https://github.com/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter10/Universal_Context_Engine.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a><br> | <a href="https://studiolab.sagemaker.aws/import/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter10/Universal_Context_Engine.ipynb"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open In Studio Lab"></a><br> |
The `Universal_Context_Engine_UI.ipynb`provides an IPython interface for interactive sessions that highlights how the industry is converging toward domainâ€‘agnostic, environmentâ€‘driven agentic systems built on transparent, contextâ€‘rich architectures. 
| <ul><li>ğŸ¬Universal_Context_Engine_UI.ipynb - January 24,2026 release</li></ul> | <a href="https://colab.research.google.com/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter10/Universal_Context_Engine_UI.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a><br> | <a href="https://www.kaggle.com/kernels/welcome?src=https://github.com/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter10/Universal_Context_Engine_UI.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" alt="Open In Kaggle"></a><br> | <a href="https://studiolab.sagemaker.aws/import/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/Chapter10/Universal_Context_Engine_UI.ipynb"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open In Studio Lab"></a><br> |
![Context Engineering Production Blueprint](https://github.com/Denis2054/Context-Engineering-for-Multi-Agent-Systems/raw/main/Chapter10/context_engineering_blueprint.svg)
</details>

## ğŸ›¡ï¸ Sovereign AI & Open-Source Engineering

For organizations requiring **100% data privacy** and **zero external API dependencies**, this repository provides a dedicated **Sovereign Path**.  
By leveraging highâ€‘reasoning openâ€‘source models like **DeepSeekâ€‘R1**, you can achieve **industrialâ€‘grade performance** entirely on your own infrastructure. <br>      
### ğŸ”‘ Key Highlights of the Sovereign Path<br>
âš¡**Performance**: Benchmarked at **~9.75 seconds** on **NVIDIA H100** hardware for complex multiâ€‘step reasoning.<br>
ğŸ”**Transparency**: Provides **100% Glassâ€‘Box observability** using local reasoning traces (`</think>` blocks).<br>
ğŸ› ï¸**Independence**: Fully disconnected execution with **no vendor lockâ€‘in** and **no unpredictable API costs**.   

[Read the DeepSeek-R1 Sovereign AI Guide](https://github.com/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/sovereign_ai/README.md)

  <li>
   <strong>Launch the DeepSeekâ€‘R1 Sovereign AI Guide</strong> in Google Colab
    <a href="https://colab.research.google.com/github/Denis2054/Context-Engineering-for-Multi-Agent-Systems/blob/main/sovereign_ai/DeepSeek%E2%80%91R1_Sovereign_AI_Guide.ipynb">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab">
    </a>
  </li>

<details open>
<summary><h2>Requirements for this book</h2></summary>

Before running the code, ensure your development environment is properly configured.

### âœ… Prerequisites
- **Python:** Version 3.10+  
- **Environment Options:** Google Colab, Kaggle, or Local

</details>


<details open> 
  <summary><h2>Requirements for this book</summary>

Before running the code, ensure your development environment is properly set up. All hands-on chapters use reproducible Python-based environments, tested in **Google Colab** and **VS Code**.

> **A Note on Latency:** The Context Engine built in this book and repository performs complex, multi-step reasoning, not simple, single-shot answers. The delay you observe in Colab is the "thinking" time, as the engine dynamically plans and executes a sequence of API calls (e.g., planning, then RAG, then generation). This is the same reason advanced platforms like Gemini or ChatGPT require a moment to "think" for complex requests, even though they benefit from significantly more powerful environments.


### âœ… Prerequisites
- **Python**: Version **3.10+**
- **Environment Options:**
  - Google Colab **or**
  - Local Python environment with:
    - `openai`
    - `pinecone-client`
    - `tiktoken`
    - `tenacity`
    - `fastapi`

### ğŸš€ Quick Start

Get up and running using cloud-based virtual machines using the Google Colab links provided for each notebook.       
No local installation is required.

#### 1. Get Your API Keys
Before running the notebooks, you will need valid API keys for the underlying services:
* **OpenAI**: Sign up and generate a key at [platform.openai.com](https://platform.openai.com/).
* **Pinecone**: Sign up and generate a free API key at [pinecone.io](https://www.pinecone.io/).

### 2. Run the Notebooks
Click the badges below to launch the notebooks directly in a pre-configured Google Colab VM. You will be asked to add your API keys to the Colab Secrets Manager upon launch.

| Chapter | Notebook | Launch |
| :--- | :--- | :--- |
| **Chapter 4** | **Context Engine** | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_USERNAME/YOUR_REPO/blob/main/Context_Engine.ipynb) |
| **Chapter X** | *Another Notebook* | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_USERNAME/YOUR_REPO/blob/main/FILENAME.ipynb) |

### âœ… Project Structure
Create a GitHub or local workspace containing at least:
- `helpers.py`
- `agents.py`
- `registry.py`
- `engine.py`
- Notebook files for each chapter

### âœ… Required API Keys
- **OpenAI** â€“ model access and moderation
- **Pinecone** â€“ vector database storage and retrieval
- **(Optional)** Google Cloud or AWS â€“ for deployment sections in Chapter 10

### âœ… System Requirements
| Requirement | Minimum | Recommended |
|------------|---------|--------------|
| CPU | Dual-core | Any modern multi-core |
| RAM | 8 GB | 16 GB or Google Colab Pro |
| GPU | Optional, but helpful for embeddings and token-heavy operations |

> **Note:** From **Chapter 5 onward**, modular components depend on earlier notebooks. Ensure your environment is configured correctly, as setup steps may not be repeated in later chapters.

### âœ… Additional Notes
- Local execution may incur **token and API costs** with large contexts.
- The **Summarizer Agent** (Chapter 6) helps reduce token usage.
- Familiarity with **RAG workflows** and **MCP-based agent orchestration** is recommended.
- Refer to **Appendix: Context Engine Reference Guide** for quick lookup of component structures and explanations.
  </details>

<details open> 
  <summary><h2>About the Author</summary>
 
### âœ… Get to know the Author
Denis Rothman is an AI systems architect and author whose work bridges foundational AI research with todayâ€™s generative and agentic architectures. A graduate of Sorbonne University and Parisâ€‘Diderot University, he designed one of the earliest patented *word2matrix* numerical encoding systems which was a precursor to modern embedding techniques. He designed one of the first industrial conversational agents, deployed as an automated language teacher for MoÃ«t & Chandon and other global companies.

Throughout his career, Denis has built largeâ€‘scale AI systems across industries, from IBM resource optimizers to worldwide Advanced Planning and Scheduling (APS) solutions, always focusing on transparent, explainable, and productionâ€‘ready architectures.

Building on decades of applied AI engineering, he has become a leading voice in the agentic era of AI, authoring influential books on transformers, RAG pipelines, businessâ€‘ready generative AI, and now *Context Engineering for Multiâ€‘Agent Systems*. His work emphasizes modelâ€‘agnostic engineering, semantic design, and the construction of resilient, domainâ€‘independent AI systems that go far beyond prompting.

Denis continues to publish handsâ€‘on frameworks, openâ€‘source architectures, and practical guides that help engineers, researchers, and organizations build the next generation of verifiable, contextâ€‘driven AI systems.

<a href="https://www.linkedin.com/in/denis-rothman-0b034043/">
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/linkedin/linkedin-original.svg" alt="LinkedIn" width="30" height="30"/>
</a>

### âœ… Other Related Books
<ul>

  <li><a href="https://www.packtpub.com/en-us/product/building-business-ready-generative-ai-systems-9781837020683">Building Business-Ready Generative AI Systems, First Edition</a></li>

  <li><a href="https://www.packtpub.com/en-us/product/rag-driven-generative-ai-9781836200901">RAG-Drive Generative AI, First Edition</a></li>

  <li><a href="https://www.packtpub.com/en-us/product/transformers-for-natural-language-processing-and-computer-vision-9781805123743">Transformers for Natural Language Processing and Computer Vision, Third Edition</a></li>

## Contributing

We welcome contributions! High interaction through Issues, PRs, and Comments helps the Context Engine grow and improves the trending visibility for the community.

### How to get started:
1.  **Check Issues:** Look for the [**good first issue**](https://github.com/Denis2054/Context-Engineering-for-Multi-Agent-Systems/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22) label for approachable tasks.
2.  **Discussions:** Join our [**Discussions tab**](https://github.com/Denis2054/Context-Engineering-for-Multi-Agent-Systems/discussions) to propose new features or "Context Chaining" techniques.
3.  **Pull Requests:** Submit improvements to the core `engine.py` or new specialized agents in `agents.py`.
 
</ul>

</details>

</details>
